# Quiz and summary

## Quiz 7

Complete [**Quiz 7**](https://docs.google.com/forms/d/e/1FAIpQLSfQW4_kH9J_G92el_PBpAtb5dQD8mp4IRVJlJTM45zuXXzwvw/viewform?usp=sf_link) to check your understanding of this topic. You are advised to score at least 50% to proceed to the next topic.

## Summary
Decision rees are another core discipline of traditional machine learning techniques, and can be much more powerful and flexible than logistic or linear regression. We can use them for regression and classification, and apply simple techniques such as bagging or boosting to reduce their variance. We can also measure feature importance, giving us an insight into how the model "thinks".

In this topic, you learnt:
- The concept of decision trees in machine learning and statistics.
- How to extend decision trees into an ensemble using Bagging and Random Forests.
- How to measure the model's feature importance for improved transparency.

## References and further reading
This material is based on the following resources:
 - **The Textbook:** James G, Witten D, Hastie T, Tibshirani R., [An Introduction to Statistical Learning](https://www.statlearning.com/), Second Edition,  Springer, 2021. [PDF](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf) {cite}`james2021statistical`
