{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 - Resampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Load dataset](#Load-dataset)\n",
    "- [Cross-Validation](#5.1-Cross-Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    LeaveOneOut,\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    ")\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "%matplotlib inline\n",
    "# plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset available on http://www-bcf.usc.edu/~gareth/ISL/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_url = \"https://github.com/pykale/transparentML/raw/main/data/Auto.csv\"\n",
    "\n",
    "auto_df = pd.read_csv(auto_url, na_values=\"?\").dropna()\n",
    "auto_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5.2 - Validation Set Approach\n",
    "Using Polynomial feature generation in scikit-learn<BR>\n",
    "http://scikit-learn.org/dev/modules/preprocessing.html#generating-polynomial-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_prop = 0.5\n",
    "p_order = np.arange(1, 11)\n",
    "r_state = np.arange(0, 10)\n",
    "\n",
    "X, Y = np.meshgrid(p_order, r_state, indexing=\"ij\")\n",
    "Z = np.zeros((p_order.size, r_state.size))\n",
    "\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Generate 10 random splits of the dataset\n",
    "for (i, j), v in np.ndenumerate(Z):\n",
    "    poly = PolynomialFeatures(int(X[i, j]))\n",
    "    X_poly = poly.fit_transform(auto_df.horsepower.values.reshape(-1, 1))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_poly, auto_df.mpg.ravel(), test_size=t_prop, random_state=Y[i, j]\n",
    "    )\n",
    "\n",
    "    regr.fit(X_train, y_train)\n",
    "    pred = regr.predict(X_test)\n",
    "    Z[i, j] = mean_squared_error(y_test, pred)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Left plot (first split)\n",
    "ax1.plot(X.T[0], Z.T[0], \"-o\")\n",
    "ax1.set_title(\"Random split of the data set\")\n",
    "\n",
    "# Right plot (all splits)\n",
    "ax2.plot(X, Z)\n",
    "ax2.set_title(\"10 random splits of the data set\")\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.set_ylabel(\"Mean Squared Error\")\n",
    "    ax.set_ylim(15, 30)\n",
    "    ax.set_xlabel(\"Degree of Polynomial\")\n",
    "    ax.set_xlim(0.5, 10.5)\n",
    "    ax.set_xticks(range(2, 11, 2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_order = np.arange(1, 11)\n",
    "r_state = np.arange(0, 10)\n",
    "\n",
    "# LeaveOneOut CV\n",
    "regr = LinearRegression()\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(auto_df)\n",
    "scores = list()\n",
    "\n",
    "for i in p_order:\n",
    "    poly = PolynomialFeatures(i)\n",
    "    X_poly = poly.fit_transform(auto_df.horsepower.values.reshape(-1, 1))\n",
    "    score = cross_val_score(\n",
    "        regr, X_poly, auto_df.mpg, cv=loo, scoring=\"neg_mean_squared_error\"\n",
    "    ).mean()\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold CV\n",
    "folds = 10\n",
    "elements = len(auto_df.index)\n",
    "\n",
    "X, Y = np.meshgrid(p_order, r_state, indexing=\"ij\")\n",
    "Z = np.zeros((p_order.size, r_state.size))\n",
    "\n",
    "regr = LinearRegression()\n",
    "\n",
    "for (i, j), v in np.ndenumerate(Z):\n",
    "    poly = PolynomialFeatures(X[i, j])\n",
    "    X_poly = poly.fit_transform(auto_df.horsepower.values.reshape(-1, 1))\n",
    "    kf_10 = KFold(n_splits=folds, random_state=Y[i, j], shuffle=True)\n",
    "    Z[i, j] = cross_val_score(\n",
    "        regr, X_poly, auto_df.mpg, cv=kf_10, scoring=\"neg_mean_squared_error\"\n",
    "    ).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Note: cross_val_score() method return negative values for the scores.\n",
    "# https://github.com/scikit-learn/scikit-learn/issues/2439\n",
    "\n",
    "# Left plot\n",
    "ax1.plot(p_order, np.array(scores) * -1, \"-o\")\n",
    "ax1.set_title(\"LOOCV\")\n",
    "\n",
    "# Right plot\n",
    "ax2.plot(X, Z * -1)\n",
    "ax2.set_title(\"10-fold CV\")\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.set_ylabel(\"Mean Squared Error\")\n",
    "    ax.set_ylim(15, 30)\n",
    "    ax.set_xlabel(\"Degree of Polynomial\")\n",
    "    ax.set_xlim(0.5, 10.5)\n",
    "    ax.set_xticks(range(2, 11, 2));"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 1
}
