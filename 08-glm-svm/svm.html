
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>8.3. Support vector machines &#8212; Transparent ML Intro</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="8.4. Quiz and summary" href="quiz-sum-ref.html" />
    <link rel="prev" title="8.2. Support vector classifiers" href="support-vec-classifier.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/transparentml-logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Transparent ML Intro</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Overview
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/pykale/transparentML/discussions">
   Discussion forum
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../00-prereq/overview.html">
   Prerequisites
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../00-prereq/linear-algebra-and-notations.html">
     Linear algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00-prereq/basic-python.html">
     Python basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00-prereq/numerical-programming.html">
     Numerical programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00-prereq/graphics.html">
     Graphics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00-prereq/loading-data.html">
     Loading data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../00-prereq/quiz-sum-ref.html">
     Quiz &amp; summary
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Primary
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01-intro/overview.html">
   1. Intro ML &amp; Transparency
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/what-is-ml.html">
     1.1. What is ML?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/ml-systems.html">
     1.2. ML systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/ml-process.html">
     1.3. ML process
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/ml-transp.html">
     1.4. ML transparency
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/knn.html">
     1.5. K-NN classifier
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/organisation.html">
     1.6. Organisation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01-intro/quiz-sum-ref.html">
     1.7. Quiz &amp; summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02-linear-reg/overview.html">
   2. Linear regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-linear-reg/simple-linear-regression.html">
     2.1. Simple linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-linear-reg/multi-linear-regression.html">
     2.2. Multiple linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-linear-reg/extension-limitation.html">
     2.3. Extensions &amp; limitations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02-linear-reg/quiz-sum-ref.html">
     2.4. Quiz &amp; summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03-logistic-reg/overview.html">
   3. Logistic regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-logistic-reg/regress-to-classify.html">
     3.1. Regress to classify?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-logistic-reg/logistic-regression.html">
     3.2. Logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03-logistic-reg/quiz-sum-ref.html">
     3.3. Quiz &amp; summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04-hypo-test-sw-dev/overview.html">
   4. Hypothesis test &amp; software dev
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-hypo-test-sw-dev/hypothesis-testing.html">
     4.1. Hypothesis testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-hypo-test-sw-dev/software-development.html">
     4.2. Software development
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04-hypo-test-sw-dev/quiz-sum-ref.html">
     4.3. Quiz &amp; summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../05-cross-val-bootstrap/overview.html">
   5. Cross validation &amp; bootstrap
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-cross-val-bootstrap/cross-validation.html">
     5.1. Cross-validation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-cross-val-bootstrap/bootstrap.html">
     5.2. Bootstrap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05-cross-val-bootstrap/quiz-sum-ref.html">
     5.3. Quiz &amp; summary
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Secondary
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../06-ftr-select-regularise/overview.html">
   6. Feature selection/regularisation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-ftr-select-regularise/feature-select.html">
     6.1. Feature selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-ftr-select-regularise/regularisation.html">
     6.2. Regularisation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06-ftr-select-regularise/quiz-sum-ref.html">
     6.3. Quiz &amp; summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07-trees-ensembles/overview.html">
   7. Trees &amp; ensembles
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-trees-ensembles/regression-trees.html">
     7.1. Regression trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-trees-ensembles/classification-trees.html">
     7.2. Classification trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-trees-ensembles/ensembles.html">
     7.3. Ensemble learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07-trees-ensembles/quiz-sum-ref.html">
     7.4. Quiz &amp; summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="overview.html">
   8. GLM &amp; SVM
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="glm.html">
     8.1. Generalised linear models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="support-vec-classifier.html">
     8.2. Support vector classifiers
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     8.3. Support vector machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="quiz-sum-ref.html">
     8.4. Quiz &amp; summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../09-pca-clustering/overview.html">
   9. PCA &amp; clustering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-pca-clustering/pca.html">
     9.1. Principal comp. analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-pca-clustering/clustering.html">
     9.2. Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09-pca-clustering/quiz-sum-ref.html">
     9.3. Quiz &amp; summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../10-deep-cnn-rnn/overview.html">
   10. Neural nets &amp; deep learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-cnn-rnn/multilayer-nn.html">
     10.1. Multilayer neural nets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-cnn-rnn/convolutional-nn.html">
     10.2. Convolutional neural nets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-cnn-rnn/recurrent-nn.html">
     10.3. Recurrent neural nets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10-deep-cnn-rnn/quiz-sum-ref.html">
     10.4. Quiz &amp; summary
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../appendix/system-transp.html">
   System transparency
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../appendix/process-transp.html">
   Process transparency
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../appendix/bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/08-glm-svm/svm.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/pykale/transparentML"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/pykale/transparentML/issues/new?title=Issue%20on%20page%20%2F08-glm-svm/svm.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/pykale/transparentML/edit/main/content/08-glm-svm/svm.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/pykale/transparentML/main?urlpath=tree/content/08-glm-svm/svm.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/pykale/transparentML/blob/main/content/08-glm-svm/svm.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification-with-nonlinear-decision-boundaries">
   8.3.1. Classification with nonlinear decision boundaries
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kernel-methods">
   8.3.2. Kernel methods
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-support-vector-machines-on-toy-data">
   8.3.3. Example: support vector machines on toy data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-svms">
     8.3.3.1. Training SVMs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluation-via-roc-curves">
     8.3.3.2. Evaluation via ROC curves
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#svm-with-more-than-two-classes">
   8.3.4. SVM with more than two classes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-vs-one">
     8.3.4.1. One-vs-one
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-vs-all">
     8.3.4.2. One-vs-all
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   8.3.5. Exercises
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Support vector machines</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification-with-nonlinear-decision-boundaries">
   8.3.1. Classification with nonlinear decision boundaries
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kernel-methods">
   8.3.2. Kernel methods
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-support-vector-machines-on-toy-data">
   8.3.3. Example: support vector machines on toy data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-svms">
     8.3.3.1. Training SVMs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluation-via-roc-curves">
     8.3.3.2. Evaluation via ROC curves
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#svm-with-more-than-two-classes">
   8.3.4. SVM with more than two classes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-vs-one">
     8.3.4.1. One-vs-one
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-vs-all">
     8.3.4.2. One-vs-all
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   8.3.5. Exercises
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="support-vector-machines">
<h1><span class="section-number">8.3. </span>Support vector machines<a class="headerlink" href="#support-vector-machines" title="Permalink to this headline">¶</a></h1>
<p>This section introduces <a class="reference external" href="https://en.wikipedia.org/wiki/Support_vector_machine">support vector machines (SVMs)</a> for nonlinear classification.</p>
<p>Watch the 9-minute video below for a visual explanation of nonlinear (polynomial) kernel and SVM.</p>
<div class="admonition-video admonition">
<p class="admonition-title">Video</p>
<iframe width="700" height="394" src="https://www.youtube.com/embed/efR1C6CvhmE?start=744&end=1205" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p><a class="reference external" href="https://www.youtube.com/embed/efR1C6CvhmE?start=744&amp;end=1205">Explaining nonlinear (polynomial) kernel and SVM, by StatQuest</a></p>
</div>
<!-- ## Nonlinear boundaries and kernel methods -->
<div class="section" id="classification-with-nonlinear-decision-boundaries">
<h2><span class="section-number">8.3.1. </span>Classification with nonlinear decision boundaries<a class="headerlink" href="#classification-with-nonlinear-decision-boundaries" title="Permalink to this headline">¶</a></h2>
<p>In binary classification, if the boundary between the two classes is linear, the <a class="reference external" href="https://pykale.github.io/transparentML/08-glm-svm/support-vec-classifier.html">support vector classifier</a> is a natural approach. However, in practice, two classes may have nonlinear boundaries between them, as the example shown in the left panel of <a class="reference internal" href="#svm8"><span class="std std-numref">Fig. 8.8</span></a> below.</p>
<!-- figclass: margin-caption -->
<div class="figure align-default" id="svm8">
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/pykale/transparentML/main/content/images/svm/svm8.png"><img alt="https://raw.githubusercontent.com/pykale/transparentML/main/content/images/svm/svm8.png" src="https://raw.githubusercontent.com/pykale/transparentML/main/content/images/svm/svm8.png" style="width: 700px;" /></a>
<p class="caption"><span class="caption-number">Fig. 8.8 </span><span class="caption-text">Left: The observations fall into two classes, with a nonlinear boundary between them. Right: The support vector classifier seeks a linear boundary, and consequently performs very poorly.</span><a class="headerlink" href="#svm8" title="Permalink to this image">¶</a></p>
</div>
<p>In <a class="reference internal" href="../02-linear-reg/extension-limitation.html"><span class="doc">Linear regression</span></a>, we discussed using higher-order polynomials as a way to fit a nonlinear relationship between the input features (predictors) and the output (response). Likewise, rather than fitting a support vector classifier using <span class="math notranslate nohighlight">\(D\)</span> features: <span class="math notranslate nohighlight">\( x_{1}, x_{2}, \cdots, x_{D} \)</span>, we could fit a support vector classifier using <span class="math notranslate nohighlight">\( 2 \times D \)</span> features: <span class="math notranslate nohighlight">\( x_{1}, x_{2}, \cdots, x_{D'}, x_{1}^2, x_{2}^2, \cdots, x_{D'}^2 \)</span>. Then the optimisation problem becomes</p>
<div class="math notranslate nohighlight" id="equation-eq-svm-polynomial">
<span class="eqno">(8.7)<a class="headerlink" href="#equation-eq-svm-polynomial" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{aligned}
&amp; \max_{\beta_0, \beta_{1,1}, \cdots, \beta_{D,2}, \epsilon_1, \cdots, \epsilon_N} M \\
&amp; \text{subject to } y_n \left(\beta_0 + \sum_{d = 1}^{D} \left(\beta_{d,1} x_{nd} + \beta_{d,2} x_{nd}^2\right)\right) \geq M(1 - \epsilon_n), \\
&amp; \sum_{d = 1}^{D} \left(\beta_{d,1}^2 + \beta_{d,2}^2\right) = 1, \epsilon_n \geq 0, \sum_{n = 1}^N \epsilon_n \leq \Xi, \text{ for } n =  1, \cdots, N.
\end{aligned}\end{split}\]</div>
<p>The decision boundary that results from Equation <a class="reference internal" href="#equation-eq-svm-polynomial">(8.7)</a> is in fact linear in the enlarged (augmented) features space of 2D features. But in the original feature space of <span class="math notranslate nohighlight">\(D\)</span> features, the decision boundary is of the form <span class="math notranslate nohighlight">\( q(\mathbf{x}) = 0 \)</span>, where <span class="math notranslate nohighlight">\( q(\cdot) \)</span> is a quadratic polynomial, so its solutions are generally nonlinear.</p>
</div>
<div class="section" id="kernel-methods">
<h2><span class="section-number">8.3.2. </span>Kernel methods<a class="headerlink" href="#kernel-methods" title="Permalink to this headline">¶</a></h2>
<p>The <em>support vector machine (SVM)</em> extends the support vector classifier by enlarging the feature space in a specific way, using <em>kernels</em>. As in the above example of using quadratic terms, the main idea is to enlarge the feature space in order to accommodate a nonlinear boundary between the classes. The kernel approach is simply a computationally efficient approach for this idea.</p>
<p>Exactly how the support vector classifier is computed is too technical to cover here. One fact from the solution to support vector classifier problem <a class="reference internal" href="support-vec-classifier.html#equation-eq-soft-margin-classifier">(8.5)</a> is that it involves only the <em>inner products</em> of the input features (observations), as opposed to the features themselves.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Mathematical details can be found <a class="reference external" href="https://scikit-learn.org/stable/modules/svm.html#svc">here</a></p>
</div>
<p>The inner product of two <span class="math notranslate nohighlight">\(D\)</span>-vectors <span class="math notranslate nohighlight">\(\mathbf{a}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> is defined as <span class="math notranslate nohighlight">\(⟨\mathbf{a}, \mathbf{b}⟩ = \sum_{d = 1}^{D} a_d b_d \)</span>. Thus, the inner product of two observations <span class="math notranslate nohighlight">\(\mathbf{x}_n\)</span> and <span class="math notranslate nohighlight">\(\mathbf{x}_{n'}\)</span> is <span class="math notranslate nohighlight">\(⟨\mathbf{x}_n, \mathbf{x}_{n'}⟩ = \sum_{d = 1}^{D} x_{nd} x_{n'd} \)</span>. As a result, the linear support vector classifier can be written as</p>
<div class="math notranslate nohighlight" id="equation-eq-svm-inner-product">
<span class="eqno">(8.8)<a class="headerlink" href="#equation-eq-svm-inner-product" title="Permalink to this equation">¶</a></span>\[\begin{equation}
f(\mathbf{x}) = \beta_0 + \sum_{n = 1}^{N} \alpha_n  ⟨\mathbf{x}, \mathbf{x}_n⟩,
\end{equation}\]</div>
<p>where there are <span class="math notranslate nohighlight">\(N\)</span> parameters <span class="math notranslate nohighlight">\(\alpha_n, \text{ for } n =  1, \cdots N \)</span>, one per training observation (sample). To estimate the parameters <span class="math notranslate nohighlight">\(\{\alpha_n\}\)</span>, all we need are the inner products of the training observations. The inner product can be denoted in the following generalised form:</p>
<div class="math notranslate nohighlight">
\[
⟨\mathbf{x}_n, \mathbf{x}_{n'}⟩ =k(\mathbf{x}_n, \mathbf{x}_{n'}),
\]</div>
<p>where <span class="math notranslate nohighlight">\( k(\cdot, \cdot) \)</span> is a <em>kernel</em> function that quantifies the similarity between two observations. For instance, we could simply take</p>
<div class="math notranslate nohighlight">
\[
k(\mathbf{x}_n, \mathbf{x}_{n'}) = \sum_{d=1}^{D} x_{nd} x_{n'd},
\]</div>
<p>which is the <em>linear kernel</em> for the support vector classifier.</p>
<p>More flexibly, we could also take</p>
<div class="math notranslate nohighlight">
\[
k(\mathbf{x}_n, \mathbf{x}_{n'}) = \left(1 + \sum_{d = 1}^{D} x_{nd} x_{n'd}\right)^{\tilde{d}},
\]</div>
<p>which is known as a <a class="reference external" href="https://en.wikipedia.org/wiki/Polynomial_kernel"><em>polynomial kernel</em></a> of degree <span class="math notranslate nohighlight">\( \tilde{d} \)</span> (a positive integer). Another popular choice is the <a class="reference external" href="https://en.wikipedia.org/wiki/Radial_basis_function_kernel">radial basis function (RBF) kernel</a> or simply <em>radial kernel</em>, which takes the form</p>
<div class="math notranslate nohighlight">
\[
k(\mathbf{x}_n, \mathbf{x}_{n'}) = \exp\left(-\gamma \sum_{d = 1}^{D} (x_{nd} - x_{n'd})^2\right),
\]</div>
<p>where <span class="math notranslate nohighlight">\( \gamma &gt; 0 \)</span> is a positive tuning parameter, i.e. hyperparameter. The radial kernel is also known as the <em>Gaussian kernel</em>. <a class="reference internal" href="#svm9"><span class="std std-numref">Fig. 8.9</span></a> below shows the decision boundaries obtained from using the polynomial (left) and radial kernels (right).</p>
<!-- figclass: margin-caption -->
<div class="figure align-default" id="svm9">
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/pykale/transparentML/main/content/images/svm/svm9.png"><img alt="https://raw.githubusercontent.com/pykale/transparentML/main/content/images/svm/svm9.png" src="https://raw.githubusercontent.com/pykale/transparentML/main/content/images/svm/svm9.png" style="width: 700px;" /></a>
<p class="caption"><span class="caption-number">Fig. 8.9 </span><span class="caption-text">Left: An SVM with a polynomial kernel of degree 3 is applied to the nonlinear data from <a class="reference internal" href="#svm8"><span class="std std-numref">Fig. 8.8</span></a>, resulting in a far more appropriate decision rule. Right: An SVM with a radial kernel is applied. In this example, either kernel is capable of capturing the decision boundary.</span><a class="headerlink" href="#svm9" title="Permalink to this image">¶</a></p>
</div>
<p>When the support vector classifier is combined with a nonlinear kernel, the resulting classifier is known as a support vector machine:</p>
<div class="math notranslate nohighlight" id="equation-eq-svm">
<span class="eqno">(8.9)<a class="headerlink" href="#equation-eq-svm" title="Permalink to this equation">¶</a></span>\[\begin{equation}
f(\mathbf{x}) = \beta_0 + \sum_{n = 1}^{N} \alpha_n k(\mathbf{x}, \mathbf{x}_n).
\end{equation}\]</div>
</div>
<div class="section" id="example-support-vector-machines-on-toy-data">
<h2><span class="section-number">8.3.3. </span>Example: support vector machines on toy data<a class="headerlink" href="#example-support-vector-machines-on-toy-data" title="Permalink to this headline">¶</a></h2>
<!-- using `scikit-learn` -->
<p>Get ready by importing the APIs needed from respective libraries.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import numpy as np
import matplotlib.pyplot as plt

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC

%matplotlib inline
</pre></div>
</div>
</div>
</div>
<p>Define a function to plot a classifier with support vectors as in the previous section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def plot_svc(svc, X, y, h=0.02, pad=0.25):
    x_min, x_max = X[:, 0].min() - pad, X[:, 0].max() + pad
    y_min, y_max = X[:, 1].min() - pad, X[:, 1].max() + pad
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.2)

    plt.scatter(X[:, 0], X[:, 1], s=70, c=y, cmap=plt.cm.Paired)
    # Support vectors indicated in plot by vertical lines
    sv = svc.support_vectors_
    plt.scatter(
        sv[:, 0], sv[:, 1], c=&quot;k&quot;, marker=&quot;x&quot;, s=100, alpha=0.5
    )  # , linewidths=1)
    plt.xlim(x_min, x_max)
    plt.ylim(y_min, y_max)
    plt.xlabel(&quot;X1&quot;)
    plt.ylabel(&quot;X2&quot;)
    plt.show()
    print(&quot;Number of support vectors: &quot;, svc.support_.size)
</pre></div>
</div>
</div>
</div>
<div class="section" id="training-svms">
<h3><span class="section-number">8.3.3.1. </span>Training SVMs<a class="headerlink" href="#training-svms" title="Permalink to this headline">¶</a></h3>
<p>Generate synthetic data randomly. Set a seed for reproducibility.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(8)
X = np.random.randn(200, 2)
X[:100] = X[:100] + 2
X[101:150] = X[101:150] - 2
y = np.concatenate([np.repeat(-1, 150), np.repeat(1, 50)])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)

plt.scatter(X[:, 0], X[:, 1], s=70, c=y, cmap=plt.cm.Paired)
plt.xlabel(&quot;X1&quot;)
plt.ylabel(&quot;X2&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/svm_6_0.png" src="../_images/svm_6_0.png" />
</div>
</div>
<p>Use the <code class="docutils literal notranslate"><span class="pre">SVC</span></code> class from <code class="docutils literal notranslate"><span class="pre">sklearn.svm</span></code> to train a support vector machine with a radial kernel. The <code class="docutils literal notranslate"><span class="pre">C</span></code> parameter is the inverse of the regularisation strength <span class="math notranslate nohighlight">\( \Xi \)</span>, and the <code class="docutils literal notranslate"><span class="pre">gamma</span></code> parameter is the inverse of the kernel width. The <code class="docutils literal notranslate"><span class="pre">fit</span></code> method trains the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>svm = SVC(C=1.0, kernel=&quot;rbf&quot;, gamma=1)
svm.fit(X_train, y_train)
plot_svc(svm, X_train, y_train)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/svm_8_0.png" src="../_images/svm_8_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of support vectors:  51
</pre></div>
</div>
</div>
</div>
<p>Let us reduce the regularisation strength <span class="math notranslate nohighlight">\( \Xi \)</span> by increasing the value of <code class="docutils literal notranslate"><span class="pre">C</span></code>. This results in a more flexible decision boundary, and will likely overfit the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>svm2 = SVC(C=100, kernel=&quot;rbf&quot;, gamma=1)
svm2.fit(X_train, y_train)
plot_svc(svm2, X_train, y_train)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/svm_10_0.png" src="../_images/svm_10_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of support vectors:  36
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Challenge</p>
<p>Can you identify signs of overfitting in the plot?</p>
</div>
<p>Choose (tune) the (hyper)parameters <code class="docutils literal notranslate"><span class="pre">C</span></code> and <code class="docutils literal notranslate"><span class="pre">gamma</span></code> using cross-validation. The <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> class from <code class="docutils literal notranslate"><span class="pre">sklearn.model_selection</span></code> performs a grid search over the specified parameter values. The <code class="docutils literal notranslate"><span class="pre">cv</span></code> parameter specifies the number of folds in the cross-validation. The <code class="docutils literal notranslate"><span class="pre">fit</span></code> method trains the model.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>tuned_parameters = {&quot;C&quot;: [0.01, 0.1, 1, 10, 100], &quot;gamma&quot;: [0.5, 1, 2, 3, 4]}
clf = GridSearchCV(
    SVC(kernel=&quot;rbf&quot;),
    tuned_parameters,
    cv=10,
    scoring=&quot;accuracy&quot;,
    return_train_score=True,
)
clf.fit(X_train, y_train)
clf.cv_results_
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;mean_fit_time&#39;: array([0.00084782, 0.00081346, 0.00084023, 0.00085504, 0.00087359,
        0.00080447, 0.00085263, 0.00088518, 0.00092402, 0.00093663,
        0.00081427, 0.00084481, 0.00094252, 0.00096495, 0.0009692 ,
        0.0008167 , 0.00085962, 0.0009762 , 0.00100927, 0.00100124,
        0.00090113, 0.00094118, 0.00097892, 0.00099318, 0.00098166]),
 &#39;std_fit_time&#39;: array([1.11795181e-04, 9.78356094e-06, 1.37721765e-05, 1.88697574e-05,
        2.46583947e-05, 1.59051463e-05, 4.89864957e-05, 1.15636943e-05,
        4.33999359e-05, 9.88574974e-06, 1.58192299e-05, 1.55558577e-05,
        2.64541073e-05, 1.95215321e-05, 5.75912897e-06, 2.37041910e-05,
        2.37358239e-05, 2.98530624e-05, 2.74638748e-05, 2.53454201e-05,
        4.60059152e-05, 4.62309794e-05, 1.86425797e-05, 2.18264494e-05,
        2.01683517e-05]),
 &#39;mean_score_time&#39;: array([0.00041704, 0.00040834, 0.00041387, 0.00040574, 0.00041335,
        0.00040221, 0.00041306, 0.0004195 , 0.00042398, 0.0004154 ,
        0.00040753, 0.00041442, 0.00042567, 0.00042379, 0.00042877,
        0.00040987, 0.00040925, 0.00041678, 0.00042481, 0.00041687,
        0.00042145, 0.00040312, 0.00041749, 0.00041726, 0.00041916]),
 &#39;std_score_time&#39;: array([3.94389013e-05, 1.23821903e-05, 1.33477998e-05, 1.00982583e-05,
        2.10549525e-05, 1.38492261e-05, 8.55138680e-06, 6.86566858e-06,
        7.89525564e-06, 1.49247174e-05, 1.12107702e-05, 6.14065553e-06,
        7.60491736e-06, 7.69560368e-06, 1.28255900e-05, 1.58760460e-05,
        7.38347350e-06, 1.08941638e-05, 1.03440697e-05, 8.05434987e-06,
        6.02205923e-05, 1.05287113e-05, 9.30165574e-06, 3.40271009e-06,
        1.43291153e-05]),
 &#39;param_C&#39;: masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,
                    1, 1, 1, 1, 1, 10, 10, 10, 10, 10, 100, 100, 100, 100,
                    100],
              mask=[False, False, False, False, False, False, False, False,
                    False, False, False, False, False, False, False, False,
                    False, False, False, False, False, False, False, False,
                    False],
        fill_value=&#39;?&#39;,
             dtype=object),
 &#39;param_gamma&#39;: masked_array(data=[0.5, 1, 2, 3, 4, 0.5, 1, 2, 3, 4, 0.5, 1, 2, 3, 4, 0.5,
                    1, 2, 3, 4, 0.5, 1, 2, 3, 4],
              mask=[False, False, False, False, False, False, False, False,
                    False, False, False, False, False, False, False, False,
                    False, False, False, False, False, False, False, False,
                    False],
        fill_value=&#39;?&#39;,
             dtype=object),
 &#39;params&#39;: [{&#39;C&#39;: 0.01, &#39;gamma&#39;: 0.5},
  {&#39;C&#39;: 0.01, &#39;gamma&#39;: 1},
  {&#39;C&#39;: 0.01, &#39;gamma&#39;: 2},
  {&#39;C&#39;: 0.01, &#39;gamma&#39;: 3},
  {&#39;C&#39;: 0.01, &#39;gamma&#39;: 4},
  {&#39;C&#39;: 0.1, &#39;gamma&#39;: 0.5},
  {&#39;C&#39;: 0.1, &#39;gamma&#39;: 1},
  {&#39;C&#39;: 0.1, &#39;gamma&#39;: 2},
  {&#39;C&#39;: 0.1, &#39;gamma&#39;: 3},
  {&#39;C&#39;: 0.1, &#39;gamma&#39;: 4},
  {&#39;C&#39;: 1, &#39;gamma&#39;: 0.5},
  {&#39;C&#39;: 1, &#39;gamma&#39;: 1},
  {&#39;C&#39;: 1, &#39;gamma&#39;: 2},
  {&#39;C&#39;: 1, &#39;gamma&#39;: 3},
  {&#39;C&#39;: 1, &#39;gamma&#39;: 4},
  {&#39;C&#39;: 10, &#39;gamma&#39;: 0.5},
  {&#39;C&#39;: 10, &#39;gamma&#39;: 1},
  {&#39;C&#39;: 10, &#39;gamma&#39;: 2},
  {&#39;C&#39;: 10, &#39;gamma&#39;: 3},
  {&#39;C&#39;: 10, &#39;gamma&#39;: 4},
  {&#39;C&#39;: 100, &#39;gamma&#39;: 0.5},
  {&#39;C&#39;: 100, &#39;gamma&#39;: 1},
  {&#39;C&#39;: 100, &#39;gamma&#39;: 2},
  {&#39;C&#39;: 100, &#39;gamma&#39;: 3},
  {&#39;C&#39;: 100, &#39;gamma&#39;: 4}],
 &#39;split0_test_score&#39;: array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.7,
        0.7, 0.7, 0.8, 0.8, 0.7, 0.7, 0.7, 0.8, 0.8, 0.7, 0.7, 0.7]),
 &#39;split1_test_score&#39;: array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,
        0.9, 0.9, 0.9, 0.8, 0.9, 0.9, 0.9, 0.8, 0.8, 0.9, 1. , 1. ]),
 &#39;split2_test_score&#39;: array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,
        0.9, 0.8, 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ]),
 &#39;split3_test_score&#39;: array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 1. , 1. , 1. ,
        1. , 0.9, 0.9, 0.9, 1. , 1. , 1. , 0.9, 0.9, 1. , 1. , 1. ]),
 &#39;split4_test_score&#39;: array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,
        0.8, 0.8, 0.9, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.7]),
 &#39;split5_test_score&#39;: array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,
        0.9, 0.9, 1. , 0.9, 0.9, 0.9, 0.9, 1. , 0.9, 0.9, 0.9, 0.9]),
 &#39;split6_test_score&#39;: array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 1. ,
        1. , 1. , 1. , 0.9, 0.8, 0.9, 0.9, 0.9, 0.8, 0.8, 0.9, 0.9]),
 &#39;split7_test_score&#39;: array([0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8,
        0.8, 0.7, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]),
 &#39;split8_test_score&#39;: array([0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 0.7,
        0.7, 0.7, 0.8, 0.8, 0.8, 0.8, 0.8, 0.7, 0.7, 0.8, 0.8, 0.8]),
 &#39;split9_test_score&#39;: array([0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 1. , 1. , 1. ,
        0.9, 0.9, 1. , 1. , 0.9, 0.9, 0.9, 0.9, 0.8, 0.9, 0.9, 0.9]),
 &#39;mean_test_score&#39;: array([0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.9 ,
        0.9 , 0.88, 0.86, 0.83, 0.91, 0.87, 0.86, 0.87, 0.87, 0.86, 0.83,
        0.86, 0.88, 0.87]),
 &#39;std_test_score&#39;: array([0.04582576, 0.04582576, 0.04582576, 0.04582576, 0.04582576,
        0.04582576, 0.04582576, 0.04582576, 0.04582576, 0.04582576,
        0.06324555, 0.06324555, 0.1077033 , 0.10198039, 0.10049876,
        0.08306624, 0.0781025 , 0.09165151, 0.09      , 0.09      ,
        0.09165151, 0.0781025 , 0.09165151, 0.09797959, 0.11      ]),
 &#39;rank_test_score&#39;: array([16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2,  2,  4, 10, 14,  1,  6,
        10,  6,  6, 10, 14, 10,  4,  6], dtype=int32),
 &#39;split0_train_score&#39;: array([0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,
        0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,
        0.95555556, 0.95555556, 0.96666667, 0.96666667, 0.98888889,
        0.95555556, 0.97777778, 1.        , 1.        , 1.        ,
        0.97777778, 1.        , 1.        , 1.        , 1.        ]),
 &#39;split1_train_score&#39;: array([0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,
        0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,
        0.92222222, 0.94444444, 0.96666667, 0.97777778, 0.98888889,
        0.95555556, 0.96666667, 0.98888889, 0.98888889, 0.98888889,
        0.97777778, 0.98888889, 0.98888889, 0.98888889, 0.98888889]),
 &#39;split2_train_score&#39;: array([0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,
        0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,
        0.93333333, 0.94444444, 0.95555556, 0.95555556, 0.96666667,
        0.95555556, 0.96666667, 0.98888889, 0.98888889, 0.98888889,
        0.96666667, 0.98888889, 0.98888889, 0.98888889, 0.98888889]),
 &#39;split3_train_score&#39;: array([0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,
        0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,
        0.94444444, 0.95555556, 0.95555556, 0.95555556, 0.97777778,
        0.94444444, 0.95555556, 0.98888889, 0.98888889, 0.98888889,
        0.95555556, 0.98888889, 0.98888889, 0.98888889, 0.98888889]),
 &#39;split4_train_score&#39;: array([0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,
        0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,
        0.93333333, 0.94444444, 0.95555556, 0.97777778, 0.98888889,
        0.95555556, 0.97777778, 0.98888889, 0.98888889, 0.98888889,
        0.98888889, 0.98888889, 0.98888889, 0.98888889, 0.98888889]),
 &#39;split5_train_score&#39;: array([0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,
        0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,
        0.93333333, 0.94444444, 0.95555556, 0.95555556, 0.97777778,
        0.94444444, 0.95555556, 0.98888889, 0.98888889, 0.98888889,
        0.95555556, 0.98888889, 0.98888889, 0.98888889, 0.98888889]),
 &#39;split6_train_score&#39;: array([0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,
        0.76666667, 0.76666667, 0.76666667, 0.76666667, 0.76666667,
        0.92222222, 0.94444444, 0.95555556, 0.95555556, 0.98888889,
        0.95555556, 0.97777778, 0.98888889, 1.        , 1.        ,
        0.97777778, 1.        , 1.        , 1.        , 1.        ]),
 &#39;split7_train_score&#39;: array([0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778,
        0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778,
        0.94444444, 0.95555556, 0.95555556, 0.96666667, 0.98888889,
        0.96666667, 0.97777778, 0.98888889, 0.98888889, 0.98888889,
        0.97777778, 0.98888889, 0.98888889, 0.98888889, 0.98888889]),
 &#39;split8_train_score&#39;: array([0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778,
        0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778,
        0.93333333, 0.94444444, 0.97777778, 0.97777778, 0.97777778,
        0.95555556, 0.97777778, 0.98888889, 0.98888889, 0.98888889,
        0.97777778, 0.98888889, 0.98888889, 0.98888889, 0.98888889]),
 &#39;split9_train_score&#39;: array([0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778,
        0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778,
        0.92222222, 0.94444444, 0.95555556, 0.96666667, 0.97777778,
        0.94444444, 0.97777778, 0.98888889, 0.98888889, 0.98888889,
        0.97777778, 0.98888889, 0.98888889, 0.98888889, 0.98888889]),
 &#39;mean_train_score&#39;: array([0.77      , 0.77      , 0.77      , 0.77      , 0.77      ,
        0.77      , 0.77      , 0.77      , 0.77      , 0.77      ,
        0.93444444, 0.94777778, 0.96      , 0.96555556, 0.98222222,
        0.95333333, 0.97111111, 0.99      , 0.99111111, 0.99111111,
        0.97333333, 0.99111111, 0.99111111, 0.99111111, 0.99111111]),
 &#39;std_train_score&#39;: array([0.00509175, 0.00509175, 0.00509175, 0.00509175, 0.00509175,
        0.00509175, 0.00509175, 0.00509175, 0.00509175, 0.00509175,
        0.0104822 , 0.00509175, 0.00737028, 0.00922958, 0.00737028,
        0.00666667, 0.00888889, 0.00333333, 0.00444444, 0.00444444,
        0.0101835 , 0.00444444, 0.00444444, 0.00444444, 0.00444444])}
</pre></div>
</div>
</div>
</div>
<p>Display the best combination of (hyper)parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>clf.best_params_
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;C&#39;: 10, &#39;gamma&#39;: 0.5}
</pre></div>
</div>
</div>
</div>
<p>Show the prediction accuracy on the test set using the respective best model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>cm = confusion_matrix(y_test, clf.best_estimator_.predict(X_test))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)
disp.plot()
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/svm_17_0.png" src="../_images/svm_17_0.png" />
</div>
</div>
<p>Compute the classification accuracy on the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>clf.best_estimator_.score(X_test, y_test)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.87
</pre></div>
</div>
</div>
</div>
<p>This is the accuracy of the best model on the test set.</p>
</div>
<div class="section" id="evaluation-via-roc-curves">
<h3><span class="section-number">8.3.3.2. </span>Evaluation via ROC curves<a class="headerlink" href="#evaluation-via-roc-curves" title="Permalink to this headline">¶</a></h3>
<p>Now, let us compare the ROC curves of two models on the training/test data with different hyperparameter <span class="math notranslate nohighlight">\(\gamma\)</span> of RBF kernel. Set <code class="docutils literal notranslate"><span class="pre">probability=True</span></code> in the <code class="docutils literal notranslate"><span class="pre">SVC</span></code> constructor if you would like to have the class probability output. Read the <a class="reference external" href="https://scikit-learn.org/stable/modules/svm.html#scores-and-probabilities">docs on scores and probabilities</a> of <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> for more details.</p>
<!-- One model is more flexible than the other. --><p>Let us use a lightly larger value of <code class="docutils literal notranslate"><span class="pre">gamma</span></code> for the first model to compare.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>svm3 = SVC(C=1, kernel=&quot;rbf&quot;, gamma=2, probability=True)
svm3.fit(X_train, y_train)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SVC(C=1, gamma=2, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">SVC</label><div class="sk-toggleable__content"><pre>SVC(C=1, gamma=2, probability=True)</pre></div></div></div></div></div></div></div>
</div>
<p>Let us use a larger value of <code class="docutils literal notranslate"><span class="pre">gamma</span></code> for the second model to compare. This will result in a more flexible decision boundary, and will likely overfit the data more.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>svm4 = SVC(C=1, kernel=&quot;rbf&quot;, gamma=50, probability=True)
svm4.fit(X_train, y_train)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SVC(C=1, gamma=50, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">SVC</label><div class="sk-toggleable__content"><pre>SVC(C=1, gamma=50, probability=True)</pre></div></div></div></div></div></div></div>
</div>
<p>Let us plot the ROC curves of the two models on the training dataset and then on the test dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_train_score3 = svm3.decision_function(X_train)
y_train_score4 = svm4.decision_function(X_train)
# comment the above two lines uncomment the following two lines to plot the ROC curves using probabilities
# y_train_score3 = svm3.predict_proba(X_train)[:, 1]
# y_train_score4 = svm4.predict_proba(X_train)[:, 1]

false_pos_rate3, true_pos_rate3, _ = roc_curve(y_train, y_train_score3)
roc_auc3 = auc(false_pos_rate3, true_pos_rate3)

false_pos_rate4, true_pos_rate4, _ = roc_curve(y_train, y_train_score4)
roc_auc4 = auc(false_pos_rate4, true_pos_rate4)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
ax1.plot(
    false_pos_rate3,
    true_pos_rate3,
    label=&quot;SVM $\gamma = 1$ ROC curve (area = %0.2f)&quot; % roc_auc3,
    color=&quot;b&quot;,
)
ax1.plot(
    false_pos_rate4,
    true_pos_rate4,
    label=&quot;SVM $\gamma = 50$ ROC curve (area = %0.2f)&quot; % roc_auc4,
    color=&quot;r&quot;,
)
ax1.set_title(&quot;Training Data&quot;)

y_test_score3 = svm3.decision_function(X_test)
y_test_score4 = svm4.decision_function(X_test)
# comment the above two lines uncomment the following two lines to plot the ROC curves using probabilities
# y_test_score3 = svm3.predict_proba(X_test)[:, 1]
# y_test_score4 = svm4.predict_proba(X_test)[:, 1]

false_pos_rate3, true_pos_rate3, _ = roc_curve(y_test, y_test_score3)
roc_auc3 = auc(false_pos_rate3, true_pos_rate3)

false_pos_rate4, true_pos_rate4, _ = roc_curve(y_test, y_test_score4)
roc_auc4 = auc(false_pos_rate4, true_pos_rate4)

ax2.plot(
    false_pos_rate3,
    true_pos_rate3,
    label=&quot;SVM $\gamma = 1$ ROC curve (area = %0.2f)&quot; % roc_auc3,
    color=&quot;b&quot;,
)
ax2.plot(
    false_pos_rate4,
    true_pos_rate4,
    label=&quot;SVM $\gamma = 50$ ROC curve (area = %0.2f)&quot; % roc_auc4,
    color=&quot;r&quot;,
)
ax2.set_title(&quot;Test Data&quot;)

for ax in fig.axes:
    ax.plot([0, 1], [0, 1], &quot;k--&quot;)
    ax.set_xlim([-0.05, 1.0])
    ax.set_ylim([0.0, 1.05])
    ax.set_xlabel(&quot;False Positive Rate&quot;)
    ax.set_ylabel(&quot;True Positive Rate&quot;)
    ax.legend(loc=&quot;lower right&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/svm_28_0.png" src="../_images/svm_28_0.png" />
</div>
</div>
<p>As we can see from the above, the more flexible model (with <span class="math notranslate nohighlight">\( \gamma = 50 \)</span>) scores better (perfectly) on the training dataset but worse on the test dataset.</p>
</div>
</div>
<div class="section" id="svm-with-more-than-two-classes">
<h2><span class="section-number">8.3.4. </span>SVM with more than two classes<a class="headerlink" href="#svm-with-more-than-two-classes" title="Permalink to this headline">¶</a></h2>
<p>So far, our discussion has been limited to the case of binary classification, i.e. the two-class setting. How can we extend SVM (or logistic regression) to the more general case where we have some arbitrary number of classes? It turns out that the concept of separating hyperplanes upon which SVMs are based does not lend itself naturally to more than two classes. There are multiple ways to extend SVMs to the multi-class settings. The two most popular solutions are the one-versus-one and one-versus-all approaches.</p>
<div class="section" id="one-vs-one">
<h3><span class="section-number">8.3.4.1. </span>One-vs-one<a class="headerlink" href="#one-vs-one" title="Permalink to this headline">¶</a></h3>
<p>Suppose that we would like to perform classification using SVMs, and there are <span class="math notranslate nohighlight">\(C\)</span> &gt; 2 classes. A one-versus-one or all-pairs approach constructs <span class="math notranslate nohighlight">\(C(C-1)/2\)</span> binary classifiers, one for each pair of classes. For example, if there are three classes, then we would construct three binary classifiers, one for each pair of classes. The first classifier would distinguish between class 1 and class 2, the second classifier would distinguish between class 1 and class 3, and the third classifier would distinguish between class 2 and class 3. To classify a new observation, we would apply each of the three classifiers, and assign the observation to the class that receives the most votes.</p>
</div>
<div class="section" id="one-vs-all">
<h3><span class="section-number">8.3.4.2. </span>One-vs-all<a class="headerlink" href="#one-vs-all" title="Permalink to this headline">¶</a></h3>
<p>The one-versus-all approach is an alternative procedure for applying SVMs in the case of <span class="math notranslate nohighlight">\(C\)</span> &gt; 2 classes. We fit <span class="math notranslate nohighlight">\(C\)</span> SVMs, each time comparing one of the <span class="math notranslate nohighlight">\(C\)</span> classes to the remaining <span class="math notranslate nohighlight">\(C − 1\)</span> classes. For example, if there are three classes, then we would fit three SVMs, one for each class. The first SVM would separate class 1 from classes 2 and 3, the second SVM would separate class 2 from classes 1 and 3, and the third SVM would separate class 3 from classes 1 and 2. To classify a new observation, we would apply each of these three classifiers, and assign the observation to the class that receives the most votes.</p>
<p>The following code shows how to train a multi-class SVM using <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>. The strategy for multi-class classification is “one vs one” internally. However, we can get “one vs rest” hyperplane by setting <code class="docutils literal notranslate"><span class="pre">decision_function_shape='ovr'</span></code> in the <code class="docutils literal notranslate"><span class="pre">SVC</span></code> object.</p>
<p>Add a third class of observations</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>XX = np.vstack([X, np.random.randn(50, 2)])
yy = np.hstack([y, np.repeat(0, 50)])
XX[yy == 0] = XX[yy == 0] + 4

plt.scatter(XX[:, 0], XX[:, 1], s=70, c=yy, cmap=plt.cm.Paired)
plt.xlabel(&quot;XX1&quot;)
plt.ylabel(&quot;XX2&quot;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/svm_31_0.png" src="../_images/svm_31_0.png" />
</div>
</div>
<p>Use SVM with an RBF kernel to fit a three-class classifier and plot the decision boundaries.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>svm5 = SVC(C=1, kernel=&quot;rbf&quot;)
svm5.fit(XX, yy)
plot_svc(svm5, XX, yy)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/svm_33_0.png" src="../_images/svm_33_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of support vectors:  125
</pre></div>
</div>
</div>
</div>
<p>We can see the classifying three classes (in 2D) is not easy, as expected.</p>
</div>
</div>
<div class="section" id="exercises">
<h2><span class="section-number">8.3.5. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<p><strong>1.</strong> All the following exercises use the <a class="reference external" href="https://github.com/pykale/transparentML/blob/main/data/Heart.csv">Heart</a>.</p>
<p>Load the <strong>Heart</strong> dataset, convert the values of variables (predictors) from category to numbers, and inspect the first five rows.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Write your code below to answer the question
</pre></div>
</div>
</div>
</div>
<p><em>Compare your answer with the reference solution below</em></p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import numpy as np
import pandas as pd

np.random.seed(2022)

heart_url = &quot;https://github.com/pykale/transparentML/raw/main/data/Heart.csv&quot;

heart_df = pd.read_csv(heart_url, index_col=0).dropna()
# converting categories
heart_df[&quot;ChestPain&quot;] = heart_df[&quot;ChestPain&quot;].factorize()[0]
heart_df[&quot;Thal&quot;] = heart_df[&quot;Thal&quot;].factorize()[0]
heart_df[&quot;AHD&quot;] = heart_df[&quot;AHD&quot;].factorize()[0]

heart_df.head(5)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Age</th>
      <th>Sex</th>
      <th>ChestPain</th>
      <th>RestBP</th>
      <th>Chol</th>
      <th>Fbs</th>
      <th>RestECG</th>
      <th>MaxHR</th>
      <th>ExAng</th>
      <th>Oldpeak</th>
      <th>Slope</th>
      <th>Ca</th>
      <th>Thal</th>
      <th>AHD</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>63</td>
      <td>1</td>
      <td>0</td>
      <td>145</td>
      <td>233</td>
      <td>1</td>
      <td>2</td>
      <td>150</td>
      <td>0</td>
      <td>2.3</td>
      <td>3</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>67</td>
      <td>1</td>
      <td>1</td>
      <td>160</td>
      <td>286</td>
      <td>0</td>
      <td>2</td>
      <td>108</td>
      <td>1</td>
      <td>1.5</td>
      <td>2</td>
      <td>3.0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>67</td>
      <td>1</td>
      <td>1</td>
      <td>120</td>
      <td>229</td>
      <td>0</td>
      <td>2</td>
      <td>129</td>
      <td>1</td>
      <td>2.6</td>
      <td>2</td>
      <td>2.0</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>37</td>
      <td>1</td>
      <td>2</td>
      <td>130</td>
      <td>250</td>
      <td>0</td>
      <td>0</td>
      <td>187</td>
      <td>0</td>
      <td>3.5</td>
      <td>3</td>
      <td>0.0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>41</td>
      <td>0</td>
      <td>3</td>
      <td>130</td>
      <td>204</td>
      <td>0</td>
      <td>2</td>
      <td>172</td>
      <td>0</td>
      <td>1.4</td>
      <td>1</td>
      <td>0.0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><strong>2</strong>. Split the loaded dataset into training and testing sets in an <span class="math notranslate nohighlight">\(80:20\)</span> ratio, then train a model using SVC using these hyperparameters <em>(C = 1, kernel = “rbf, gamma = 0.01, probability = true)</em> where kernel =”rbf” means it is a support vector machine (SVM) extend the SVC by enlarging the feature space in a specific way, using rbf kernel.Finally, show the number of support vectors and AUROC of this trained model on the test set. (Use <span class="math notranslate nohighlight">\(2022\)</span> as the random seed value)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Write your code below to answer the question
</pre></div>
</div>
</div>
</div>
<p><em>Compare your answer with the reference solution below</em></p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

np.random.seed(2022)

X = heart_df.drop([&quot;AHD&quot;], axis=1)
y = heart_df[&quot;AHD&quot;]


X_train, X_test, y_train, y_test = train_test_split(X, y.ravel(), test_size=0.2)

svm = SVC(C=1, kernel=&quot;rbf&quot;, gamma=0.01, probability=True)
svm.fit(X_train, y_train)
print(&quot;Number of Support vectors: &quot;, len(svm.support_vectors_))

y_test_score = svm.decision_function(X_test)

fpr, tpr, _ = roc_curve(y_test, y_test_score)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, label=&quot;AUC=&quot; + str(roc_auc))
plt.ylabel(&quot;True Positive Rate&quot;)
plt.xlabel(&quot;False Positive Rate&quot;)
plt.legend(loc=4)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of Support vectors:  234
</pre></div>
</div>
<img alt="../_images/svm_43_1.png" src="../_images/svm_43_1.png" />
</div>
</div>
<p><strong>3.</strong> Train another model in the same manner as in <strong>Exercise 2</strong>, but with the hyperparameter regularisation strength <span class="math notranslate nohighlight">\(C\)</span> set to <span class="math notranslate nohighlight">\(100\)</span>. Show the number of support vectors and AUROC of this trained model on the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Write your code below to answer the question
</pre></div>
</div>
</div>
</div>
<p><em>Compare your answer with the reference solution below</em></p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>svm = SVC(C=100, kernel=&quot;rbf&quot;, gamma=0.01, probability=True)
svm.fit(X_train, y_train)
print(&quot;Number of Support vectors: &quot;, len(svm.support_vectors_))

y_test_score = svm.decision_function(X_test)

fpr, tpr, _ = roc_curve(y_test, y_test_score)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, label=&quot;AUC=&quot; + str(roc_auc))
plt.ylabel(&quot;True Positive Rate&quot;)
plt.xlabel(&quot;False Positive Rate&quot;)
plt.legend(loc=4)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of Support vectors:  233
</pre></div>
</div>
<img alt="../_images/svm_47_1.png" src="../_images/svm_47_1.png" />
</div>
</div>
<p><strong>4.</strong> Using <strong>GridSearchCV</strong>, fine-tune the SVM hyperparameters (<span class="math notranslate nohighlight">\(C\)</span> and <span class="math notranslate nohighlight">\(gamma\)</span>) on the training dataset (using <span class="math notranslate nohighlight">\(10\)</span>-fold cross-validation) for <span class="math notranslate nohighlight">\(C\)</span> values of <span class="math notranslate nohighlight">\(0.001\)</span>, <span class="math notranslate nohighlight">\(0.01\)</span>, <span class="math notranslate nohighlight">\(0.1\)</span>, <span class="math notranslate nohighlight">\(5\)</span> and <span class="math notranslate nohighlight">\(gamma\)</span> values of <span class="math notranslate nohighlight">\(0.001\)</span>, <span class="math notranslate nohighlight">\(0.01\)</span>, <span class="math notranslate nohighlight">\(0.1\)</span>, <span class="math notranslate nohighlight">\(0.5\)</span>, <span class="math notranslate nohighlight">\(1\)</span>.Display the best hyperparameters value for <span class="math notranslate nohighlight">\(C\)</span> and <span class="math notranslate nohighlight">\(gamma\)</span>. (Use the roc_auc scoring for choosing the best model and it’s hyperparameters).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Write your code below to answer the question
</pre></div>
</div>
</div>
</div>
<p><em>Compare your answer with the reference solution below</em></p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.model_selection import GridSearchCV

tuned_parameters = {&quot;C&quot;: [0.01, 0.1, 1, 10, 100], &quot;gamma&quot;: [0.001, 0.01, 0.1, 0.5, 1]}
clf = GridSearchCV(
    SVC(kernel=&quot;rbf&quot;, probability=True),
    tuned_parameters,
    cv=10,
    scoring=&quot;roc_auc&quot;,
    return_train_score=True,
)
clf.fit(X_train, y_train)
print(&quot;\nOptimal parameters : &quot;, clf.best_params_)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimal parameters :  {&#39;C&#39;: 1, &#39;gamma&#39;: 0.001}
</pre></div>
</div>
</div>
</div>
<p><strong>5.</strong> Finally, using the best hyperparameters from <strong>Exercise 4</strong>, train another SVM model on the training dataset and display the AUROC of this trained model on the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Write your code below to answer the question
</pre></div>
</div>
</div>
</div>
<p><em>Compare your answer with the reference solution below</em></p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>svm = SVC(C=1, kernel=&quot;rbf&quot;, gamma=0.001, probability=True)
svm.fit(X_train, y_train)
print(&quot;Number of Support vectors: &quot;, len(svm.support_vectors_))

y_test_score = svm.decision_function(X_test)

fpr, tpr, _ = roc_curve(y_test, y_test_score)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, label=&quot;AUC=&quot; + str(roc_auc))
plt.ylabel(&quot;True Positive Rate&quot;)
plt.xlabel(&quot;False Positive Rate&quot;)
plt.legend(loc=4)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of Support vectors:  189
</pre></div>
</div>
<img alt="../_images/svm_55_1.png" src="../_images/svm_55_1.png" />
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./08-glm-svm"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="support-vec-classifier.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">8.2. </span>Support vector classifiers</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="quiz-sum-ref.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">8.4. </span>Quiz and summary</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Haiping Lu and Shuo Zhou<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>