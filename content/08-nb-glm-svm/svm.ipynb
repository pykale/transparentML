{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9 - Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Lab: 9.6.1 Support Vector Classifier](#9.6.1-Support-Vector-Classifier)\n",
    "- [Lab: 9.6.2 Support Vector Machine](#9.6.2-Support-Vector-Machine)\n",
    "- [Lab: 9.6.3 ROC Curves](#9.6.3-ROC-Curves)\n",
    "- [Lab: 9.6.4 SVM with Multiple Classes](#9.6.4-SVM-with-Multiple-Classes)\n",
    "- [Lab: 9.6.5 Application to Gene Expression Data](#9.6.5-Application-to-Gene-Expression-Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6.1 Support Vector Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to plot a classifier with support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svc(svc, X, y, h=0.02, pad=0.25):\n",
    "    x_min, x_max = X[:, 0].min() - pad, X[:, 0].max() + pad\n",
    "    y_min, y_max = X[:, 1].min() - pad, X[:, 1].max() + pad\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.2)\n",
    "\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=70, c=y, cmap=plt.cm.Paired)\n",
    "    # Support vectors indicated in plot by vertical lines\n",
    "    sv = svc.support_vectors_\n",
    "    plt.scatter(sv[:, 0], sv[:, 1], c=\"k\", marker=\"|\", s=100, linewidths=\"1\")\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.xlabel(\"X1\")\n",
    "    plt.ylabel(\"X2\")\n",
    "    plt.show()\n",
    "    print(\"Number of support vectors: \", svc.support_.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random data: 20 observations of 2 features and divide into two classes.\n",
    "np.random.seed(5)\n",
    "X = np.random.randn(20, 2)\n",
    "y = np.repeat([1, -1], 10)\n",
    "\n",
    "X[y == -1] = X[y == -1] + 1\n",
    "plt.scatter(X[:, 0], X[:, 1], s=70, c=y, cmap=plt.cm.Paired)\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier with linear kernel.\n",
    "svc = SVC(C=1.0, kernel=\"linear\")\n",
    "svc.fit(X, y)\n",
    "\n",
    "plot_svc(svc, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using a smaller cost parameter (C=0.1) the margin is wider, resulting in more support vectors.\n",
    "svc2 = SVC(C=0.1, kernel=\"linear\")\n",
    "svc2.fit(X, y)\n",
    "plot_svc(svc2, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the optimal C parameter by cross-validation\n",
    "tuned_parameters = [{\"C\": [0.001, 0.01, 0.1, 1, 5, 10, 100]}]\n",
    "clf = GridSearchCV(\n",
    "    SVC(kernel=\"linear\"),\n",
    "    tuned_parameters,\n",
    "    cv=10,\n",
    "    scoring=\"accuracy\",\n",
    "    return_train_score=True,\n",
    ")\n",
    "clf.fit(X, y)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.001 is best according to GridSearchCV.\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating test data\n",
    "np.random.seed(1)\n",
    "X_test = np.random.randn(20, 2)\n",
    "y_test = np.random.choice([-1, 1], 20)\n",
    "X_test[y_test == 1] = X_test[y_test == 1] - 1\n",
    "\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], s=70, c=y_test, cmap=plt.cm.Paired)\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc2 : C = 0.1\n",
    "y_pred = svc2.predict(X_test)\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred), index=svc.classes_, columns=svc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc3 = SVC(C=0.001, kernel=\"linear\")\n",
    "svc3.fit(X, y)\n",
    "\n",
    "# svc3 : C = 0.001\n",
    "y_pred = svc3.predict(X_test)\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred), index=svc3.classes_, columns=svc3.classes_\n",
    ")\n",
    "# The misclassification is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the test data so that the classes are really seperable with a hyperplane.\n",
    "X_test[y_test == 1] = X_test[y_test == 1] - 1\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], s=70, c=y_test, cmap=plt.cm.Paired)\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc4 = SVC(C=10.0, kernel=\"linear\")\n",
    "svc4.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svc(svc4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the margin. Now there is one misclassification: increased bias, lower variance.\n",
    "svc5 = SVC(C=1, kernel=\"linear\")\n",
    "svc5.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svc(svc5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6.2 Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating test data\n",
    "np.random.seed(8)\n",
    "X = np.random.randn(200, 2)\n",
    "X[:100] = X[:100] + 2\n",
    "X[101:150] = X[101:150] - 2\n",
    "y = np.concatenate([np.repeat(-1, 150), np.repeat(1, 50)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], s=70, c=y, cmap=plt.cm.Paired)\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=1.0, kernel=\"rbf\", gamma=1)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svc(svm, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing C parameter, allowing more flexibility\n",
    "svm2 = SVC(C=100, kernel=\"rbf\", gamma=1.0)\n",
    "svm2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svc(svm2, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{\"C\": [0.01, 0.1, 1, 10, 100], \"gamma\": [0.5, 1, 2, 3, 4]}]\n",
    "clf = GridSearchCV(\n",
    "    SVC(kernel=\"rbf\"),\n",
    "    tuned_parameters,\n",
    "    cv=10,\n",
    "    scoring=\"accuracy\",\n",
    "    return_train_score=True,\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, clf.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15% of test observations misclassified\n",
    "clf.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6.3 ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the ROC curves of two models on train/test data. One model is more flexible than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm3 = SVC(C=1, kernel=\"rbf\", gamma=2)\n",
    "svm3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More flexible model\n",
    "svm4 = SVC(C=1, kernel=\"rbf\", gamma=50)\n",
    "svm4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_score3 = svm3.decision_function(X_train)\n",
    "y_train_score4 = svm4.decision_function(X_train)\n",
    "\n",
    "false_pos_rate3, true_pos_rate3, _ = roc_curve(y_train, y_train_score3)\n",
    "roc_auc3 = auc(false_pos_rate3, true_pos_rate3)\n",
    "\n",
    "false_pos_rate4, true_pos_rate4, _ = roc_curve(y_train, y_train_score4)\n",
    "roc_auc4 = auc(false_pos_rate4, true_pos_rate4)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "ax1.plot(\n",
    "    false_pos_rate3,\n",
    "    true_pos_rate3,\n",
    "    label=\"SVM $\\gamma = 1$ ROC curve (area = %0.2f)\" % roc_auc3,\n",
    "    color=\"b\",\n",
    ")\n",
    "ax1.plot(\n",
    "    false_pos_rate4,\n",
    "    true_pos_rate4,\n",
    "    label=\"SVM $\\gamma = 50$ ROC curve (area = %0.2f)\" % roc_auc4,\n",
    "    color=\"r\",\n",
    ")\n",
    "ax1.set_title(\"Training Data\")\n",
    "\n",
    "y_test_score3 = svm3.decision_function(X_test)\n",
    "y_test_score4 = svm4.decision_function(X_test)\n",
    "\n",
    "false_pos_rate3, true_pos_rate3, _ = roc_curve(y_test, y_test_score3)\n",
    "roc_auc3 = auc(false_pos_rate3, true_pos_rate3)\n",
    "\n",
    "false_pos_rate4, true_pos_rate4, _ = roc_curve(y_test, y_test_score4)\n",
    "roc_auc4 = auc(false_pos_rate4, true_pos_rate4)\n",
    "\n",
    "ax2.plot(\n",
    "    false_pos_rate3,\n",
    "    true_pos_rate3,\n",
    "    label=\"SVM $\\gamma = 1$ ROC curve (area = %0.2f)\" % roc_auc3,\n",
    "    color=\"b\",\n",
    ")\n",
    "ax2.plot(\n",
    "    false_pos_rate4,\n",
    "    true_pos_rate4,\n",
    "    label=\"SVM $\\gamma = 50$ ROC curve (area = %0.2f)\" % roc_auc4,\n",
    "    color=\"r\",\n",
    ")\n",
    "ax2.set_title(\"Test Data\")\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.plot([0, 1], [0, 1], \"k--\")\n",
    "    ax.set_xlim([-0.05, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the more flexible model scores better on training data but worse on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6.4 SVM with Multiple Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a third class of observations\n",
    "np.random.seed(8)\n",
    "XX = np.vstack([X, np.random.randn(50, 2)])\n",
    "yy = np.hstack([y, np.repeat(0, 50)])\n",
    "XX[yy == 0] = XX[yy == 0] + 4\n",
    "\n",
    "plt.scatter(XX[:, 0], XX[:, 1], s=70, c=yy, cmap=plt.cm.prism)\n",
    "plt.xlabel(\"XX1\")\n",
    "plt.ylabel(\"XX2\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm5 = SVC(C=1, kernel=\"rbf\")\n",
    "svm5.fit(XX, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svc(svm5, XX, yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6.5 Application to Gene Expression Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In R, I exported the dataset from package 'ISLR' to csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"Data/Khan_xtrain.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "y_train = (\n",
    "    pd.read_csv(\"Data/Khan_ytrain.csv\").drop(\"Unnamed: 0\", axis=1).as_matrix().ravel()\n",
    ")\n",
    "X_test = pd.read_csv(\"Data/Khan_xtest.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "y_test = (\n",
    "    pd.read_csv(\"Data/Khan_ytest.csv\").drop(\"Unnamed: 0\", axis=1).as_matrix().ravel()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train counts\n",
    "pd.Series(y_train).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test counts\n",
    "pd.Series(y_test).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model gives identical results to the svm() of the R package e1071, also based on libsvm library.\n",
    "svc = SVC(kernel=\"linear\")\n",
    "\n",
    "# This model is based on liblinear library and gives 100 score on the test data.\n",
    "# svc = LinearSVC()\n",
    "\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, svc.predict(X_train))\n",
    "cm_df = pd.DataFrame(cm.T, index=svc.classes_, columns=svc.classes_)\n",
    "cm_df.index.name = \"Predicted\"\n",
    "cm_df.columns.name = \"True\"\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, svc.predict(X_test))\n",
    "cm_df = pd.DataFrame(cm.T, index=svc.classes_, columns=svc.classes_)\n",
    "cm_df.index.name = \"Predicted\"\n",
    "cm_df.columns.name = \"True\"\n",
    "print(cm_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pykale')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
